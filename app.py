from flask import Flask, jsonify, request, send_from_directory
import boto3
from datetime import datetime, timedelta, timezone
import json
import time
import psutil  # ì‹¤ì‹œê°„ CPU ì¸¡ì •ìš©

app = Flask(__name__)

# ==========================
# ê¸°ë³¸ ì„¤ì •
# ==========================
INSTANCE_ID = "i-0e7de4c65819cd64a"
REGION = "ap-northeast-2"

cloudwatch = boto3.client("cloudwatch", region_name=REGION)
bedrock = boto3.client("bedrock-runtime", region_name=REGION)
sns = boto3.client("sns", region_name=REGION)

# ğŸ‘‰ SNS Topic ARN 
SNS_TOPIC_ARN = "arn:aws:sns:ap-northeast-2:907569901932:monitoring-alerts"

# ğŸ‘‰ Bedrock Haiku ëª¨ë¸ ID 
MODEL_ID = "anthropic.claude-3-haiku-20240307-v1:0"

# ì¿¨ë‹¤ìš´
ANALYZE_COOLDOWN_SECONDS = 30
ALERT_COOLDOWN_SECONDS = 300
LAST_ANALYZE_TS = 0
LAST_ALERT_TS = 0


# ==========================
# index.html ì„œë¹™
# ==========================
@app.route("/")
def dashboard():
    return send_from_directory("static", "index.html")


# ==========================
# CloudWatch CPU (5ë¶„ í‰ê· )
# ==========================
@app.route("/cpu")
def cpu_report():
    try:
        end = datetime.now(timezone.utc)
        start = end - timedelta(hours=1)

        resp = cloudwatch.get_metric_statistics(
            Namespace="AWS/EC2",
            MetricName="CPUUtilization",
            Dimensions=[{"Name": "InstanceId", "Value": INSTANCE_ID}],
            StartTime=start,
            EndTime=end,
            Period=300,
            Statistics=["Average"],
            Unit="Percent",
        )

        datapoints = resp.get("Datapoints", [])
        datapoints.sort(key=lambda p: p["Timestamp"])

        return jsonify({
            "status": "ok",
            "timestamps": [dp["Timestamp"].isoformat() for dp in datapoints],
            "values": [dp["Average"] for dp in datapoints],
        })

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


# ==========================
# ì‹¤ì‹œê°„ CPU (psutil)
# ==========================
@app.route("/cpu_live")
def cpu_live():
    try:
        cpu = psutil.cpu_percent(interval=0.1)
        now = datetime.now(timezone.utc).isoformat()
        return jsonify({
            "status": "ok",
            "timestamp": now,
            "cpu_percent": cpu,
        })
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


# ==========================
# ë©”íŠ¸ë¦­ ìš”ì•½ í•¨ìˆ˜
# ==========================
def get_metric_summary(instance_id, region, period_minutes=60):
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(minutes=period_minutes)

    metrics_def = {
        "CPUUtilization": ("Percent", ["Average", "Maximum"]),
        "NetworkIn": ("Bytes", ["Average", "Maximum"]),
        "NetworkOut": ("Bytes", ["Average", "Maximum"]),
    }

    summary = {
        "instance_id": instance_id,
        "region": region,
        "period_minutes": period_minutes,
        "time_range_utc": {
            "start": start_time.isoformat(),
            "end": end_time.isoformat(),
        },
        "metrics": {},
    }

    for metric_name, (unit, stats) in metrics_def.items():
        resp = cloudwatch.get_metric_statistics(
            Namespace="AWS/EC2",
            MetricName=metric_name,
            Dimensions=[{"Name": "InstanceId", "Value": instance_id}],
            StartTime=start_time,
            EndTime=end_time,
            Period=300,
            Statistics=stats,
            Unit=unit,
        )
        datapoints = resp.get("Datapoints", [])
        if not datapoints:
            summary["metrics"][metric_name] = {
                "average": None,
                "maximum": None,
                "datapoint_count": 0,
            }
            continue

        averages = [dp.get("Average") for dp in datapoints if "Average" in dp]
        maximums = [dp.get("Maximum") for dp in datapoints if "Maximum" in dp]

        summary["metrics"][metric_name] = {
            "average": sum(averages) / len(averages) if averages else None,
            "maximum": max(maximums) if maximums else None,
            "datapoint_count": len(datapoints),
        }

    return summary


# ==========================
# Haiku í”„ë¡¬í”„íŠ¸
# ==========================
AI_ANALYZE_SYSTEM_PROMPT = """
ë„ˆëŠ” AWS ì¸í”„ë¼ ìš´ì˜ì„ ë•ëŠ” SRE/DevOps AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ë‹¤.
ì•„ë˜ ë©”íŠ¸ë¦­ ìš”ì•½(CPU, NetworkIn, NetworkOut)ì„ ë°”íƒ•ìœ¼ë¡œ
JSON ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼:

{
    "status": "OK" | "WARNING" | "CRITICAL",
    "summary": "3ë¬¸ì¥ ì´í•˜ ìš”ì•½",
    "suspected_causes": ["ì›ì¸1", "ì›ì¸2"],
    "recommended_actions": ["ì¡°ì¹˜1", "ì¡°ì¹˜2"]
}
"""


def build_ai_prompt(metric_summary):
    m = metric_summary["metrics"]
    fmt = lambda x: "N/A" if x is None else round(x, 2)

    lines = [
        f"ê¸°ê°„: ìµœê·¼ {metric_summary['period_minutes']}ë¶„",
        f"ì‹œê°„ ë²”ìœ„: {metric_summary['time_range_utc']['start']} ~ {metric_summary['time_range_utc']['end']}",
        "",
        f"CPU í‰ê· : {fmt(m['CPUUtilization']['average'])}, ìµœëŒ€: {fmt(m['CPUUtilization']['maximum'])}",
        f"NetworkIn í‰ê· : {fmt(m['NetworkIn']['average'])}, ìµœëŒ€: {fmt(m['NetworkIn']['maximum'])}",
        f"NetworkOut í‰ê· : {fmt(m['NetworkOut']['average'])}, ìµœëŒ€: {fmt(m['NetworkOut']['maximum'])}",
        "",
        "í˜„ì¬ ì¸ìŠ¤í„´ìŠ¤ ìƒíƒœë¥¼ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ í‰ê°€í•´ì¤˜.",
    ]
    return "\n".join(lines)


# ==========================
# Bedrock Haiku í˜¸ì¶œ
# ==========================
def call_haiku(metric_summary):

    payload = {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"text": AI_ANALYZE_SYSTEM_PROMPT},
                    {"text": build_ai_prompt(metric_summary)},
                ],
            }
        ],
        "inferenceConfig": {
            "maxTokens": 400,
            "temperature": 0.3,
        }
    }

    resp = bedrock.converse(
        modelId=MODEL_ID,
        messages=payload["messages"],
        inferenceConfig=payload["inferenceConfig"]
    )

    text = resp["output"]["message"]["content"][0]["text"]

    try:
        return json.loads(text)
    except:
        return {
            "status": "WARNING",
            "summary": "AI ì‘ë‹µì„ íŒŒì‹±í•˜ì§€ ëª»í•¨",
            "suspected_causes": ["JSON í˜•ì‹ ì˜¤ë¥˜"],
            "recommended_actions": ["í”„ë¡¬í”„íŠ¸ ìˆ˜ì • í•„ìš”"],
            "raw": text,
        }


# ==========================
# SNS ì•ŒëŒ ë°œì†¡
# ==========================
def send_alert(metric_summary, ai_result):
    global LAST_ALERT_TS

    now = time.time()
    if now - LAST_ALERT_TS < ALERT_COOLDOWN_SECONDS:
        return {
            "alert_sent": False,
            "reason": "cooldown",
            "cooldown_remaining": ALERT_COOLDOWN_SECONDS - int(now - LAST_ALERT_TS),
        }

    cpu = metric_summary["metrics"]["CPUUtilization"]
    avg, mx = cpu["average"], cpu["maximum"]

    cpu_cond = (avg and avg > 70) or (mx and mx > 90)
    ai_cond = ai_result.get("status") == "CRITICAL"

    if not (cpu_cond or ai_cond):
        return {"alert_sent": False, "reason": "no_condition_matched"}

    subject = "[EC2 ALERT] CPU ë˜ëŠ” AI ê²½ê³  ê°ì§€"
    message = json.dumps(ai_result, ensure_ascii=False, indent=2)

    sns.publish(
        TopicArn=SNS_TOPIC_ARN,
        Subject=subject,
        Message=message,
    )

    LAST_ALERT_TS = now
    return {"alert_sent": True, "subject": subject}


# ==========================
# /analyze
# ==========================
@app.route("/analyze")
def analyze():
    global LAST_ANALYZE_TS

    now = time.time()
    if now - LAST_ANALYZE_TS < ANALYZE_COOLDOWN_SECONDS:
        return jsonify({
            "status": "TOO_FREQUENT",
            "retry_after_seconds": ANALYZE_COOLDOWN_SECONDS - int(now - LAST_ANALYZE_TS),
        }), 429

    LAST_ANALYZE_TS = now

    minutes = int(request.args.get("minutes", 60))

    metric_summary = get_metric_summary(INSTANCE_ID, REGION, minutes)
    ai_result = call_haiku(metric_summary)
    alert = send_alert(metric_summary, ai_result)

    return jsonify({
        "status": "OK",
        "metric_summary": metric_summary,
        "ai_report": ai_result,
        "alert": alert,
        "minutes": minutes,
    })


# ==========================
# ì‹¤í–‰
# ==========================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
